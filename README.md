# Naive Bayes 邮件文本分类

该项目是一个基于朴素贝叶斯算法的英文垃圾邮件分类器，用于测试这一伟大的概率发现，使用Python编写。该分类器能够根据给定的文本数据集进行训练，并根据训练得到的模型对新的文本进行分类。该分类器的主要思想是利用贝叶斯定理和假设各特征之间相互独立的朴素假设，来计算一个文本属于某个类别的概率。

## 项目结构

该项目的文件结构如下：

```
├── origin_data
│   ├── 0
│   │   ├── xxx.txt
│   │   └── xxxx.txt
│   └── 1
│       ├── xxx.txt
│       └── xxxx.txt
├── model.py
├── main.py
├── create.py
├── train.py
├── model.pkl
├── data.csv
└── test.txt
```
origin_data文件夹：用于存放原始训练数据集。

create.py：用于将原始数据集转化为csv格式的data文件。

model.py：包含NaiveBayes类的定义，用于训练和预测文本分类模型。

train.py：用于训练模型并将模型保存到文件model.pkl中。

main.py：用于加载模型，并读取test.txt中的邮件进行文本分类预测。

## 使用方法

### 1. 准备数据集

origin_data文件夹内有0和1两个子文件夹，每个子文件夹中可以包含多个文本文件，每个文件代表一个邮件文本样本。

其中类型0代表非垃圾邮件（即正常邮件），类型1为垃圾邮件。

接着运行create.py，创建格式化的data.csv数据集文件。

### 2. 训练模型

确保目录下存在data.csv，运行train.py，生成预训练模型文件。

### 3. 模型预测

编写test.txt内容，运行main.py程序，将输出[x1, x2]，分别代表为为正常、垃圾邮件的概率。

## 实现原理

首先，我们需要将每个电子邮件表示为特征向量。可以使用各种特征，例如电子邮件中包含的单词、链接、附件等。这里，我们使用电子邮件中包含的单词作为特征。对于每个电子邮件，我们将计算每个单词在电子邮件中出现的次数，然后将这些计数作为特征向量的元素。

然后，我们可以使用贝叶斯公式来计算给定特征向量的情况下每个类别的后验概率。具体来说，我们需要计算以下两个概率：

1. 类别的先验概率：在训练集中，垃圾邮件和非垃圾邮件的比例分别是多少。

2. 特征在给定类别下的条件概率：给定类别（例如垃圾邮件），每个单词出现的条件概率是多少。

通过这些概率，我们可以使用贝叶斯公式计算给定特征向量下每个类别的后验概率。我们可以将后验概率最高的类别作为分类结果。

在朴素贝叶斯中，对于某个类别 $c$，我们需要计算样本 $x$ 属于该类别的后验概率 $P(c|x)$，即 $P(c|x) = \frac{P(x|c)P(c)}{P(x)}$，其中 $P(x|c)$ 是似然概率，$P(c)$ 是先验概率，$P(x)$ 是边缘概率。

计算后验概率时，我们需要计算 $P(x|c)$ 和 $P(c)$ 的乘积，但由于浮点精度的限制，当乘积非常小的时候，程序可能无法正确处理。为了避免这种情况，我们可以将后验概率的对数取出来，即

$$
\log P(c|x) = \log P(x|c) + \log P(c) - \log P(x)
$$

但是在实际计算时，当 $\log P(x|c) + \log P(c)$ 的值非常小（接近 $-\infty$）时，直接使用 $\exp$ 函数进行还原会出现下溢（计算结果趋向于 $0$），这时我们可以将所有的 $\log P(x|c) + \log P(c)$ 都减去最大值，从而避免了计算 $\exp$ 时出现下溢的问题。

本程序的数据大多为自行编造，数据集内容暂时较少，还需进一步完善。